{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSCI-511 - Data preprocessing and acquisition\n",
    "\n",
    "## Application to retrieve real time tweets on climate change.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Team Members\n",
    "\n",
    "Abhinav Chaudhary\n",
    "\n",
    "Amar Kumar\n",
    "\n",
    "Astha Jain\n",
    "\n",
    "Erica Racine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A)  Tweet Streamer - Connects to Twitter streaming API using tweepy and sends the tweet to rabbitmq queue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tweepy.streaming import StreamListener\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import Stream\n",
    "import pika\n",
    "\n",
    "class StreamTweets(StreamListener):\n",
    "    def __init__(self,chan):\n",
    "         self.channel = chan\n",
    "    def on_data(self, tweet):\n",
    "        try:\n",
    "            self.channel.basic_publish(exchange='', routing_key='twitterqueue', body=tweet)\n",
    "        except Exception as e:\n",
    "            print(\"Error: %s\" % e)\n",
    "\n",
    "    def on_error(self,status_code):\n",
    "        print(status_code)\n",
    "\n",
    "    def on_exception(self, exception):\n",
    "        print(exception)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "        consumer_key = \"ULItewxGYkR8ueTHxVpP7aVmE\"\n",
    "        consumer_secret = \"tTYMqhqDs5hKQxvBfnz1KiUWaJKEq3PtXjniYvycdjmJteUYaQ\"\n",
    "        access_token = \"1186025638622367745-Mb6BZ1vNn1dlOTgYs5MadKwO45M496\"\n",
    "        access_token_secret = \"mntEfhh9o53i3m5jfSwRilCYOvGht42gby5eMOlSkzQ6r\"\n",
    "\n",
    "        auth = OAuthHandler(consumer_key,consumer_secret)\n",
    "        auth.set_access_token(access_token,access_token_secret)\n",
    "\n",
    "        connection = pika.BlockingConnection(\n",
    "            pika.ConnectionParameters(host='localhost'))\n",
    "        channel = connection.channel()\n",
    "\n",
    "        channel.queue_declare(queue='twitterqueue')\n",
    "\n",
    "        tracklist = [\"#climatechange\", \"#climatechangeisreal\", \"#actonclimate\", \"#globalwarming\",\n",
    "                     \"#climatechangehoax\", \"#climatedeniers\", \"#climatechangeisfalse\", \"#globalwarminghoax\",\n",
    "                     \"#climatechangenotreal\",\"#greentweets\", \"#carbondioxide\" ,\"#CO2\", \"#carbonemissions\",\n",
    "                     \"#greenhousegas\",\"#greenhousegasses\",\"#greenhousegasemissions\",'#climatechange','#nature',\n",
    "                     '#environment', '#climate', '#climatestrike', '#globalwarming', '#savetheplanet', '#sustainability',\n",
    "                     '#gretathunberg', '#zerowaste', '#ecofriendly', '#climatecrisis', '#fridaysforfuture', '#earth',\n",
    "                     '#climateaction', '#climatechangeisreal', '#plasticfree', '#gogreen', '#savetheearth', '#sustainable',\n",
    "                     '#climatejustice', '#pollution', '#recycle', '#green', '#eco', '#climateemergency', '#extinctionrebellion',\n",
    "                     '#vegan', '#saveourplanet']\n",
    "\n",
    "        stream = Stream(auth,listener = StreamTweets(channel))\n",
    "        print(\"Starting twitter stream..\")\n",
    "        stream.filter(track = tracklist, languages = [\"en\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B)  Tweet processor - Receives tweet from rabbitmq queue and processes the data before writing it to the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pika\n",
    "import json\n",
    "import csv\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "import os\n",
    "\n",
    "\n",
    "def process_tweet(data):\n",
    "    try:\n",
    "            id = data[\"id\"]\n",
    "            text = data[\"text\"].strip()\n",
    "            created_at = data[\"created_at\"]\n",
    "            username = data[\"user\"][\"name\"]\n",
    "            user_id = data[\"user\"][\"id\"]\n",
    "            user_location = data[\"user\"][\"location\"]\n",
    "            quoted_full_text = None\n",
    "            retweet_full_text = None\n",
    "            if 'quoted_status' in data and 'extended_tweet' in data['quoted_status'].keys():\n",
    "                     quoted_full_text = data['quoted_status']['extended_tweet']['full_text'].strip()\n",
    "            elif 'retweeted_status' in data and 'extended_tweet' in data['retweeted_status'].keys():\n",
    "                     retweet_full_text = data['retweeted_status']['extended_tweet']['full_text'].strip()\n",
    "            ps = PorterStemmer()\n",
    "            stop_words = set(stopwords.words('english'))\n",
    "            if quoted_full_text is None and retweet_full_text is None:\n",
    "                     httpremoved = re.sub(r\"http\\S+\", \"\",text)\n",
    "                     no_special_charac = re.sub('[^A-Za-z0-9\\s]+', '', httpremoved)\n",
    "                     words = word_tokenize(no_special_charac)\n",
    "                     not_common_words = [w for w in words if not w in stop_words]\n",
    "                     stemmed_words = [ps.stem(w) for w in not_common_words]\n",
    "                     row = [id,created_at,username,user_id,user_location,text,stemmed_words]\n",
    "            elif quoted_full_text is None:\n",
    "                     httpremoved = re.sub(r\"http\\S+\", \"\", retweet_full_text)\n",
    "                     no_special_charac = re.sub('[^A-Za-z0-9\\s]+', '', httpremoved)\n",
    "                     words = word_tokenize(no_special_charac)\n",
    "                     not_common_words = [w for w in words if not w in stop_words]\n",
    "                     stemmed_words = [ps.stem(w) for w in not_common_words]\n",
    "                     row = [id,created_at,username,user_id,user_location,retweet_full_text,stemmed_words]\n",
    "            elif retweet_full_text is None:\n",
    "                     httpremoved = re.sub(r\"http\\S+\", \"\", quoted_full_text)\n",
    "                     no_special_charac = re.sub('[^A-Za-z0-9\\s]+', '', httpremoved)\n",
    "                     words = word_tokenize(no_special_charac)\n",
    "                     not_common_words = [w for w in words if not w in stop_words]\n",
    "                     stemmed_words = [ps.stem(w) for w in not_common_words]\n",
    "                     row = [id, created_at, username, user_id, user_location, quoted_full_text,stemmed_words]\n",
    "            writer.writerow(row)\n",
    "    except Exception as e:\n",
    "            file.close()\n",
    "            print(\"Error: %s\" %e)\n",
    "\n",
    "def callback(ch, method, properties, body):\n",
    "    data = json.loads(body)\n",
    "    process_tweet(data)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    header = ['tweet_id', 'created_at', 'username', 'user_id', 'user_location', 'text','stemmed_words']\n",
    "    if not os.path.isfile('/home/tweet/tweet_data.csv'):\n",
    "            file =  open(\"/home/tweet/tweet_data.csv\", \"a\",encoding=\"utf-8\")\n",
    "            writer = csv.writer(file,delimiter=',')\n",
    "            writer.writerow(header)\n",
    "    else:\n",
    "        file = open(\"/home/tweet/tweet_data.csv\", \"a\", encoding=\"utf-8\")\n",
    "        writer = csv.writer(file, delimiter=',')\n",
    "    connection = pika.BlockingConnection(pika.ConnectionParameters(host='localhost'))\n",
    "    channel = connection.channel()\n",
    "    channel.queue_declare(queue='twitterqueue')\n",
    "    channel.basic_consume(\n",
    "    queue='twitterqueue', on_message_callback=callback, auto_ack=True)\n",
    "    print('Waiting for Tweets..')\n",
    "\n",
    "    channel.start_consuming()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C)  Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>username</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_location</th>\n",
       "      <th>text</th>\n",
       "      <th>stemmed_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34544</th>\n",
       "      <td>1201157109074866177</td>\n",
       "      <td>Sun Dec 01 15:12:25 +0000 2019</td>\n",
       "      <td>John Snowmountainer</td>\n",
       "      <td>1003949688465354752</td>\n",
       "      <td>NaN</td>\n",
       "      <td>What are your options when it comes to replacing your boiler?\\nhttps://t.co/Pvpn949j7h \\n.\\n#energy #energyefficiency #epc #renewableenergy #heating #cooling #environmentallyfriendly #energyefficient #homeowner #home #tips #savingmoney #sustainable #co2 #carbonfootprint</td>\n",
       "      <td>['what', 'option', 'come', 'replac', 'boiler', 'energi', 'energyeffici', 'epc', 'renewableenergi', 'heat', 'cool', 'environmentallyfriendli', 'energyeffici', 'homeown', 'home', 'tip', 'savingmoney', 'sustain', 'co2', 'carbonfootprint']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28508</th>\n",
       "      <td>1201139355378765825</td>\n",
       "      <td>Sun Dec 01 14:01:53 +0000 2019</td>\n",
       "      <td>Its @InnoDeckoks</td>\n",
       "      <td>1289740650</td>\n",
       "      <td>Nairobi</td>\n",
       "      <td>The world again meets in Spain on to advance work on tackling #ClimateEmergency #ClimateCrisis Our #YOUTH message to #COP25Madrid is simple: science has shown we have no time, the people have shown we want #ClimateActionNow. Remember the people you serve and youth you'll leave! https://t.co/fHYp64PZnA</td>\n",
       "      <td>['the', 'world', 'meet', 'spain', 'advanc', 'work', 'tackl', 'climateemerg', 'climatecrisi', 'our', 'youth', 'messag', 'cop25madrid', 'simpl', 'scienc', 'shown', 'time', 'peopl', 'shown', 'want', 'climateactionnow', 'rememb', 'peopl', 'serv', 'youth', 'youll', 'leav']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50683</th>\n",
       "      <td>1201204145971175425</td>\n",
       "      <td>Sun Dec 01 18:19:20 +0000 2019</td>\n",
       "      <td>DJMartin</td>\n",
       "      <td>1051231829754343424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"It is heartbreaking for us that you have to come here and beg for your lives, that you have to come here and beg for the right to have a normal life\".\\n\\nhttps://t.co/10iiTsGcW6\\n\\n#SchoolStrike4Climate #YouthStrike4Climate #ExtinctionRebellion</td>\n",
       "      <td>['It', 'heartbreak', 'us', 'come', 'beg', 'live', 'come', 'beg', 'right', 'normal', 'life', 'schoolstrike4clim', 'youthstrike4clim', 'extinctionrebellion']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42665</th>\n",
       "      <td>1201179935823605760</td>\n",
       "      <td>Sun Dec 01 16:43:08 +0000 2019</td>\n",
       "      <td>Kore Strong</td>\n",
       "      <td>960564431833845760</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"Bondar questioned how the three trustees got elected to sit on a board of education, given their denial of recognized science.\"\\n\\nThe thought police are coming after school board trustees now. It's total indoctrination. \\n#ClimateChangeHoax \\n#bcpoli \\nhttps://t.co/M1fUzJIqqM</td>\n",
       "      <td>['bondar', 'question', 'three', 'truste', 'got', 'elect', 'sit', 'board', 'educ', 'given', 'denial', 'recogn', 'scienc', 'the', 'thought', 'polic', 'come', 'school', 'board', 'truste', 'it', 'total', 'indoctrin', 'climatechangehoax', 'bcpoli']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38796</th>\n",
       "      <td>1201169098681585665</td>\n",
       "      <td>Sun Dec 01 16:00:04 +0000 2019</td>\n",
       "      <td>Digital Sages</td>\n",
       "      <td>859204328430678016</td>\n",
       "      <td>New Jersey, USA</td>\n",
       "      <td>RT @aTravelCompanio: #London tops list of world’s most #vegan friendly cities\\nhttps://t.co/9VIaxcPcM1 #foodies https://t.co/ouRkhqk6BA</td>\n",
       "      <td>['RT', 'atravelcompanio', 'london', 'top', 'list', 'world', 'vegan', 'friendli', 'citi', 'foodi']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"tweet_data.csv\")\n",
    "display(HTML(df.sample(5).to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D) README"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Steps to run the application:\n",
    "\n",
    "1.) Download docker from https://www.docker.com/products/docker-desktop for your operating system.\n",
    "\n",
    "2.) Create a working directory and copy the following files in to the directory.\n",
    "\n",
    "a) dockerfile\n",
    "b) tweet_processor.py\n",
    "c) tweet_streamer.py\n",
    "\n",
    "3.) Open terminal and run the following commands(cd working directory) from inside the directory created in step 2.\n",
    "    \n",
    "    docker build -t project/tweeter-streamer .       <-  Note \".\" is included in the command.\n",
    "\n",
    "    Replace the path /home/abhinav/Project in the following command with a directory on your \n",
    "    operating system where the output file will be written.\n",
    "    \n",
    "    docker run -it --name twitter_streaming_app --restart=always -v /home/abhinav/Project:/home/tweet project/tweeter-streamer:latest\n",
    "    \n",
    "    Check the running container with the following command:\n",
    "    \n",
    "    docker ps\n",
    "    \n",
    "    Use the following commands to start and stop the script.\n",
    "    \n",
    "    (Container id is obtained by running the docker ps command)\n",
    "    \n",
    "    docker start <container id>       \n",
    "    docker stop <container id>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E)  Docker commands"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "docker build -t project/tweeter-streamer .\n",
    "\n",
    "docker run -it --restart=always -v /home/abhinav/Project:/home/tweet project/tweeter-streamer:latest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F) Docker File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FROM python\n",
    "\n",
    "RUN apt-get update && \\\n",
    "    apt-get install -y rabbitmq-server &&\\\n",
    "    apt install -y python3-pip && \\\n",
    "    pip3 install tweepy  && \\ \n",
    "    pip3 install pika  && \\\n",
    "    pip3 install nltk\n",
    "\n",
    "RUN python3 -m nltk.downloader -d /usr/local/share/nltk_data stopwords punkt\n",
    "RUN mkdir -p /home/application\n",
    "\n",
    "COPY tweet_processor.py /home/application\n",
    "COPY tweet_streamer.py /home/application\n",
    "\n",
    "RUN mkdir -p /home/tweet\n",
    "\n",
    "VOLUME [\"/home/tweet\"]\n",
    "\n",
    "CMD service rabbitmq-server start; exec python3 /home/application/tweet_processor.py & exec python3 /home/application/tweet_streamer.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
